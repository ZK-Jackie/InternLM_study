<div style="border-bottom: 4px solid black; width: 100%; box-sizing: border-box; text-align: center; padding-top: 0.1rem;" align="center">
    <h1>书生大模型实战营「第3期」学员笔记<br/><span>基础岛 - 书生大模型全链路开源体系</span></h1>
</div>
<div style="text-align: center;" align="center">
    笔记记录人：ZK-Jackie&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;笔记记录时间：2024.7.18
</div>

## 目录

- [1 大模型发展背景](#1-大模型发展背景)
  - [1.1 大模型成为关键热门词](#11-大模型成为关键热门词)
  - [1.2 大模型成为发展通用人工智能的重要途径](#12-大模型成为发展通用人工智能的重要途径)
- [2 书生·浦语大模型全链路开源体系](#2-书生浦语大模型全链路开源体系)
  - [2.1 书生·浦语大模型开源历程](#21-书生浦语大模型开源历程)
  - [2.2 InternLM2.5](#22-internlm25)
  - [2.3 XTuner](#23-xtuner)
  - [2.4 OpenCompass](#24-opencompass)
  - [2.5 LMDeploy](#25-lmdeploy)
  - [2.6 Lagent](#26-lagent)
- [3 总结](#3-总结)
- [参考资料](#参考资料)
- [备注](#备注)

## 1 大模型发展背景

### 1.1 大模型成为关键热门词

根据综述文献的统计，自 2018 年以来 arXiv 发布的论文中，论文标题和摘要中含 LL(Large Language) 和 LLM(Large Language Model) 关键词的论文呈指数级上涨，从最初的“无人问津”到如今的上万次关注量；这与 ChatGPT 的发展与发布有较大关系。

Open AI 自 2018 年起，致力于 GPT 的发展与研究，从 2018 年 GPT-1 至 2020 年的 GPT-3，多年的研究与发展最终令其在全世界人眼中大放异彩。在 GPT-4 发布的 2 个月后即月活破亿，热度超过 TikTok。

当下，大模型已经成为人工智能领域的关键热门词，也是人们关注的焦点。人工智能这一概念在 LLM 的发展下又出现了更多新的可能性。

### 1.2 大模型成为发展通用人工智能的重要途径

2006 年起，有关于人工智能的研究就不断进行着，多年的发展下，通用大模型越来越受到欢迎，从整体上看，人工智能正从原来的的“专用模型”向“通用模型”发展转型。

- 专用模型：特定任务，一个模型，一个问题（如 Alpha GO、人脸识别、德州扑克人工智能等）
- 通用模型：一个模型，多种任务，多种模态（如 ChatGPT）

典型地，通用大语言模型 ChatGPT，在聊天、文字处理、问答、代码编写等方面都有较好表现，特别是 GPT-4 的发布，也让人们看到了通用大语言模型在图像识别、语音处理方面的潜力，向人们展示了更高阶人工智能的潜在途径、让人们找到了发展未来的可能性。

## 2 书生·浦语大模型全链路开源体系

在大语言模型快速发展的背景下，上海人工智能实验室投入大量研究力量于大语言模型的研发工作中，书生·浦语大模型全链路开源体系由此诞生。

书生·浦语坚持相信开源和社区的力量能够帮助人工智能的进一步发展与创新，书生·浦语全系列开源的同时，也提供了一系列开源的工具与服务，帮助用户更好地参与到大模型、人工智能的研究、开发与应用中。

从研发到应用，书生·浦语提供了一整套完整的开源体系，包括：

- 万卷-CC：高质量英文网络文本数据集
- InternEvo：轻量级大模型预训练框架
- Xtuner：轻量化大模型微调工具
- LMDeploy：LLM 轻量化高效部署工具
- InternLM：预训练大语言模型
- OpenCompass：客观评估大模型性能的开源工具
- Lagent：大语言模型智能体框架
- ……

### 2.1 书生·浦语大模型开源历程

2023 年 6 月，上海人工智能实验室发布千亿级参数的 InternLM 大语言模型，同年 7 月便发布了支持 8K 语境、26 种语言、全面开源、免费商用的 InternLM-7B 模型，同时开源有关 InternLM 训练、微调、部署、评测、应用等一系列数据集及工具与框架，此后的一年多的时间里，实验室不断对模型及工具进行升级，现已经推出了 InternLM 的 2.5 版本，并继续坚持开源贡献、成果共享的理念不断发展。

### 2.2 InternLM2.5

InternLM2.5 是上海人工智能实验室最新发布的第 2.5 代的 InternLM 系列大语言模型，开源了适用于实际场景的 70 亿参数的基础模型和 Chat 模型。它一共具有三个版本，分别是 InternLM2.5-7B、InternLM2.5-Chat-7B 和 InternLM2.5-7B-Chat-1M，具有以下特点：

- **出色的推理能力**：在数学推理方面表现出色，超越了 Llama3 和 Gemma2-9B 等模型。
- **1M 语境窗口**：在 1M 长的语境下几乎完美地找到了“大海捞针”的能力，在长语境任务（如 LongBench）上表现出色。
- **更强的工具使用**：InternLM2.5 支持从 100 多个网页中获取信息，对应的实现将很快在 Lagent 中发布。InternLM2.5 在指令跟随、工具选择和反思方面具有更好的工具利用能力。

在多种任务的表现上，InternLM2.5 也有着不俗的表现，如数学推理、长语境任务、工具使用等，都有着领先的性能。

这些优势都为 InternLM2.5 从单纯的模型走向实际应用中提供了更多的可能性，也为用户提供了更好的体验。

### 2.3 XTuner

XTuner 是上海人工智能实验室开发的一个大语言模型&多模态模型微调工具箱，由 MMRazor 和 MMDeploy 联合开发，它内部集成了大量的微调场景，用户可以通过配置文件的形式来进行微调，即使是 0 基础的非专业人员也能够轻松上手。它具有以下特点：

- **傻瓜化**：以配置文件的形式封装了大部分微调场景，0 基础的非专业人员也能一键开始微调。
- **轻量级**：对于 7B 参数量的 LLM，微调所需的最小显存仅为 8GB，消费级显卡和 colab 都可以轻松运行。
- **多模态**：支持多模态微调，可以让用户更好地利用多模态数据。
- **适配高**：它适配多种开源模型生态，支持多种微调算法，内部的优化加速算法也使得开发者无需关注复杂的显存优化与计算加速细节，也可轻松达到微调目的。

### 2.4 OpenCompass

大模型评测是大模型研究的一个重要环节。通过对大模型能力的量化评估，与其他大模型的参数上的对比，可以更好地了解大模型的性能，也可以更好地指导大模型的研究与开发。

OpenCompass 便是一款专注于大模型评测的开源工具。OpenCompass 由上海人工智能实验室开发，专注于进行大模型的客观评测，它具有以下特点：

- **全面**：OpenCompass 覆盖了大模型的学科、语言、知识、理解和推理能力等多个方面，可以全面评估大模型的性能。
- **客观**：OpenCompass 采用了客观的评测标准，可以更好地评估大模型的性能，避免了主观因素的干扰。
- **开源**：OpenCompass 是一款开源工具，用户可以自由使用，也可以根据自己的需求进行二次开发。
- **易用**：OpenCompass 的使用非常简单，用户只需要按照文档的指引，即可轻松进行大模型的评测。

<div class="image-box" style="text-align: center;" align="center">
    <img class="image" style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://github.com/tonysy/opencompass/assets/7881589/90dbe1c0-c323-470a-991e-2b37ab5350b2"
    alt="Lagent" />
    <br/>
    <div class="caption" style="border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenCompass</div>
    <br/>
</div>

最新发布的 OpenCompass 2.0 版本，提供了更加完备的评测体系，也支持了更多的评测标准，更多的模型评测，更多的评测任务，更多的评测数据，更多的评测结果。结合强大的社区支持OpenCompass 2.0 的评测结果得以社区验证、共享，为大模型的发展提供了更多的可能性。

OpenCompass 继续发展，为用户提供高度个性化的评测服务、为走向全球领先的大模型开源评测体系而不断努力。

### 2.5 LMDeploy

大模型具有内存开销巨大、动态Shape而模型结构相对简单的特点，它的体量往往难以由低存储设备部署承担，且相关推理、服务相应问题也十分具有挑战性而难以解决。部署大模型则需要一套具有模型并行、低比特量化、Attention优化、计算和访存优化、Continuous Batching的方案。

LMDeploy 便是为了解决这些问题，为用户提供完整地部署而生。 LMDeploy 是上海人工智能实验室开发的一款 LLM 轻量化高效部署工具，它可以帮助用户更好地将 LLM 部署到生产环境中，提高 LLM 的部署效率，降低部署成本，提高部署质量。

<div class="image-box" style="text-align: center;" align="center">
    <img class="image" style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://github.com/InternLM/lmdeploy/assets/4560679/8e455cf1-a792-4fa8-91a2-75df96a2a5ba"
    alt="LMDeploy" />
    <br/>
    <div class="caption" style="border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">LMDeploy</div>
    <br/>
</div>

其自研的 TurboMind 引擎，在各种规模的模型上，每秒处理的请求数是 vLLM 的 1.36 ~ 1.85 倍。在静态推理能力方面，TurboMind 4bit 模型推理速度（out token/s）远高于 FP16/BF16 推理。在小 batch 时，提高到 2.4 倍。

在使用方面，LMDeploy 内置了完备易用的工具链，可以使用 LMDeploy 就实现量化、推理、服务的全流程，并且与 OpenCompass 提供的评测工具完美结合，可以帮助用户更好地评估模型的性能。LMDeploy 也提供了和 OpenAI 接口兼容的服务，可以帮助用户更好地将模型部署到生产环境中。

### 2.6 Lagent

Lagent 是上海人工智能实验室开发的一款大语言模型智能体框架，它可以帮助用户更好地将大语言模型转变为多种类型的智能体，并提供了一些典型工具为大语言模型赋能。

<div class="image-box" style="text-align: center;" align="center">
    <img class="image" style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="https://github.com/InternLM/lagent/assets/24351120/cefc4145-2ad8-4f80-b88b-97c05d1b9d3e"
    alt="Lagent" />
    <br/>
    <div class="caption" style="border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Lagent 结构</div>
    <br/>
</div>

Lagent 的设计遵循智能体应用的一般流程，包括 Model、Action 和 Agent 三个部分。用户可以通过继承和装饰的方式，打造自己个人的工具集，不论是 InternLM 还是 GPT 均可适配。Lagent 还提供了一些典型的工具，如 stream_chat 接口，可以帮助用户更好地进行流式输出。

结合 LMDeploy，Lagent 可以帮助用户更好地将大语言模型部署到生产环境中，实现更多的智能体在生产环境中的应用。

### 2.7 其他

此外，上海人工智能实验室也在积极探索大模型在生活中更多领域的应用场景，除了上述的应用或工具外，AI Lab 保持开源的态度，也提供了诸多开源工具、应用及框架，如：

- [InternVL: 多模态对话模型](https://github.com/OpenGVLab/InternVL)
- [茴香豆：智能聊天机器人](https://github.com/InternLM/HuixiangDou)
- [MinerU: 高质量数据提取工具](https://github.com/opendatalab/MinerU)
- [MindSearch: 基于大模型的多模态搜索引擎](https://github.com/InternLM/MindSearch)
- ...

我也坚信随着大模型的发展，书生·浦语大模型全链路开源体系将会不断完善，为用户提供更好的体验，也为大模型的发展提供更多的可能性。

## 3 总结

书生·浦语大模型全链路开源体系提供了一整套完整的开源体系，从数据、预训练、微调、部署、评测、应用等一系列工具与框架，帮助用户更好地参与到大模型、人工智能的研究、开发与应用中。这些工具与框架的开源，也为大模型的发展提供了更多的可能性，也为用户提供了更好的体验。

## 参考资料

- [InternLM Group - GitHub](https://github.com/InternLM/)
- [书生·浦语](https://internlm.intern-ai.org.cn/)
- [OpenCompass司南](https://opencompass.org.cn/home)
- [OpenXLab浦源](https://openxlab.org.cn/home)


## 备注

由于本次学习开始及完成较早，部分内容可能与最新学习内容有所出入，仅供参考。
