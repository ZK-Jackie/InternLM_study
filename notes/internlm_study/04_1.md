> # 第四讲 XTuner 大模型单卡低成本微调实战
> <p>主讲人：汪周谦</p> <p>笔记记录人：ZK-Jackie</p> <p>笔记记录时间：2024.2.12</p>

## 目录
- **一、Finetune简介**
  - **1. LLM的局限性**
  - **2. 突破LLM局限的方法**
- **二、XTuner简介
- **三、总结**
- **二、LangChain和基于LangChain搭建本地应用介绍**
  - **1. 基本介绍**
  - **2. 基于LangChain搭建本地应用的基本流程**
- **三、总结**
- **四、课后作业**

## 前言
大语言模型是在海量文本内容上，以无监督或半监督的方式进行训练的模型，它的训练数据集通常包含了大量的文本数据，如维基百科、新闻、书籍、网页等。这些模型在训练过程中，通过学习文本数据中的统计规律，从而学习到了丰富的语言知识，包括语法、语义、逻辑等。

但是，由于训练数据的局限性，大语言模型在实际应用中还存在一些局限性，如知识时效性受限、专业能力有限、定制化成本高等问题。为了解决这些问题，令他能够有更好的应用价值，当下也有两种基本思路解决它，分别是通过Finetune（微调）和RAG（检索增强生成）。

在上一节课程中我们已经学习如何使用RAG范式，利用LangChain解决这一问题，本节课程中我们将学习如何通过Finetune（微调）的方式，来解决大语言模型的局限性。

## 一、Finetune简介
LLM 的下游应用中，增量预训练和指令跟随是经常会用到两种的微调模式。

- 增量预训练
  - 在原有的预训练模型上，继续训练，提供更多数据，以适应特定领域的语言模型。
  - 使用场景:让基座模型学习到一些新知识，如某个垂类领域的常识
  - 训练数据:文章、书籍、代码等

- 指令跟随微调
  - 提供一些指令，让模型学会对话模板，根据人类指令进行对话
  - 使用场景:让模型学会对话模板，根据人类指令进行对话
  - 训练数据:高质量的对话、问答数据

下面将针对两种微调手段进行详细介绍。


### 1. 指令跟随微调
指令跟随微调是为了得到能够实际对话的LLM，介绍指令跟随微调前，需要先了解如何使用LLM进行对话。在实际对话时，通常会有三种角色——
- System：给定一些上下文信息，比如“你是一个安全的 A1助手”
- User：实际用户，会提出一些问题，比如“世界第一高峰是?”
- Assistant：根据 User 的输入，结合 System 的上下文信息，做出回答，比如“珠穆朗玛峰”

### 2. 增量预训练
增量预训练是为了让模型学会一些新的知识，比如某个垂类领域的常识。在增量预训练中，我们需要提供一些领域相关的数据，让模型学会这些领域的知识。而这一过程只有一种角色即Assistant，它会根据提供的领域数据，学会这些领域的知识。

## 二、XTuner简介
XTuner是由书生浦语开发的微调框架，是一个大模型微调工具箱，支持从Hugging Face和Model Scope中加载模型和数据集，支持多款开源大模型，允许让用户在消费级显卡条件下进行大模型微调，免除复杂的数据格式，帮助开发人员专注于数据本身。

## 三、总结
本节课程主要介绍了使用Finetune（微调）的方式来解决大语言模型局限性的方法。首先，讨论了大语言模型在实际应用中存在的一些局限性，包括知识时效性受限、专业能力有限、定制化成本高等问题。随后详细介绍了通过Finetune的两种微调手段：指令跟随微调和增量预训练。

指令跟随微调旨在让模型学会实际对话，通过给定上下文信息和用户提出的问题，让助手角色根据这些信息做出回答，从而实现实际对话。而增量预训练则是为了让模型学会新的领域知识，通过提供领域相关的数据，让助手角色学会这些领域的知识。

此外，还介绍了XTuner微调框架，它是一个大模型微调工具箱，支持从Hugging Face和Model Scope中加载模型和数据集，允许在消费级显卡条件下进行大模型微调，提供了便捷的微调工具。

## [四、课后作业](04_2.md)