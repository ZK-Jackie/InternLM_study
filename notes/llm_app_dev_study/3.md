<div style="border-bottom: 4px solid black; width: 100%; box-sizing: border-box; text-align: center; padding-top: 0.1rem;" align="center">
    <h1>Datawhale AI 夏令营 LLM 应用开发实战笔记<br/><span>Task3：实现 RAG 应用</span></h1>
</div>
<div style="text-align: center;" align="center">
    笔记记录人：ZK-Jackie&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;笔记记录时间：2024.7.18
</div>

## 目录

- [一、RAG 应用介绍](#一rag-应用介绍)
  - [1. RAG 介绍](#1-rag-介绍)
  - [2. RAG 应用实现](#2-rag-应用实现)
    - [（1）文本向量化](#1文本向量化)
    - [（2）文本检索](#2文本检索)
    - [（3）文本生成](#3文本生成)
- [二、RAG 应用构建](#二rag-应用构建)
  - [1. 使用 LlamaIndex 框架构建 RAG 应用](#1-使用-llmaindex-框架构建-rag-应用)
  - [2. 使用 LangChain 框架构建 RAG 应用](#2-使用-langchain-框架构建-rag-应用)
- [三、总结](#三总结)
- [参考文章](#参考文章)

## 一、RAG 应用介绍

RAG（Retrieval-Augmented Generation）是一种基于检索的生成式模型，结合了检索式和生成式的优点，可以实现更加准确和高效的问答系统。

要实现 RAG 应用，首先需要了解 RAG 模型的基本原理和实现方法。

### 1. RAG 介绍

RAG 模型是一种基于检索的生成式模型，主要由两部分组成：

- **Retriever**：检索器，用于从大量的文本数据中检索出与问题相关的文本片段。
- **Generator**：生成器，用于根据检索到的文本片段生成答案。

RAG 模型的基本原理是，首先使用检索器从大量的文本数据中检索出与问题相关的文本片段，然后使用生成器根据检索到的文本片段生成答案。这也意味着必须使用一定的模型，将数据整理成检索器可以处理的格式，然后再使用检索器从中检索出相关的文本片段。

### 2. RAG 应用实现

在这些过程中，都依赖于 Embedding 技术。Embedding 技术是一种将文本数据转换为数字向量表示的技术，可以将文本数据转换为向量表示，然后使用向量表示进行检索和生成。

要实现 RAG 应用，首先需要采用 Embedding 技术，将文本信息向量化，随后可以采用向量数据库的方式，将向量化的文本信息存储在数据库中，然后使用检索器从数据库中检索出相关的文本片段，最后使用生成器根据检索到的文本片段生成答案。

整体过程如`图 1`所示。

<div class="image-box" style="text-align: center;" align="center">
    <img class="image" style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="../assets/llm_app_dev_study/10.png"
    alt="RAG" />
    <br/>
    <div class="caption" style="border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">图 1 RAG</div>
</div>

总的来说，构建这样一个 RAG 应用主要需要实现三部分内容，下文将分别介绍这三部分的实现。

#### （1）文本向量化

文本向量化是将文本数据转换为数字向量表示的过程，当下，已有多种开源的词向量化库，如 sentence-transformers、transformers 等，可以直接使用这些库来实现文本向量化。

直接调用这些库，实现了文本向向量的转变后，还需将这些内容存储到向量数据库中存储起来。向量数据库也有多种好用的开源库，如 Chroma、Faiss 等，参考相关文档，可以实现向量数据库的搭建。

#### （2）文本检索

在构建了向量数据库后，可以使用检索器从数据库中检索出相关的文本片段。检索器可以使用当下热门的 LangChain 框架内部提供的对应的检索器模块，也可以使用各向量数据库提供的检索器模块。

向检索器输入一段文字，检索器会返回与输入文字相关的文本片段，这些文本片段可以用于生成器生成答案。

#### （3）文本生成

生成器综合用户输入的问题，综合检索器检索到的文本片段，便能够总体分析、生成答案。对于本次竞赛，生成器可以采用当下热门的 LLM 模型，如 GPT-4、GLM-4、Qwen 等，也可以使用其他生成式模型作为生成器的核心。


## 二、RAG 应用构建

了解了一个 RAG 应用的基本原理和实现方法后，我们下面将介绍如何使用 LlamaIndex 框架或 LangChain 框架构建一个带前端网页界面 RAG 应用。

### 1. 使用页面框架构建 RAG 应用

在 LLM 应用构建中，常使用成熟的快速开发框架构建 LLM 前端界面，如 Streamlit、Gradio、Flask、Django 等。这些框架都提供了丰富的组件和模板，可以快速搭建一个美观、实用的 LLM 前端界面，使用 Streamlit 和 Gradio 框架搭建 LLM 应用原型是最为常见的。

Streamlit 和 Gradio 都是 Python 的快速开发框架，可以帮助用户快速搭建一个交互式的 Web 应用。使用这两个框架，可以将 LLM 模型部署到 Web 端，实现用户输入问题，模型生成答案的功能。他们都提供了多种便捷的语法，使得我们仅需编写少量代码，便可实现一个呈现形式多样，交互良好的 LLM 应用。

后文主要使用 Gradio 实现页面的构建。

### 2. 使用 LlamaIndex 框架构建 RAG 应用

LlamaIndex 是一个 AI 框架，用于简化将私有数据与公共数据集成到大型语言模型（LLM）中的应用程序中。它提供了数据 ingestion、 indexing 和查询的工具，使其成为生成式 AI 需求的可靠解决方案。

LlamaIndex 主要包括以下几个组件:
- 数据连接器：帮助连接现有数据源和数据格式（如 API、PDF 等），并将这些数据转换为 LlamaIndex 可用的格式。
- 数据索引：帮助结构化数据以适应不同的用例。加载了来自不同数据源的数据后，如何将它们分割、定义关系和组织，以便无论您想要解决的问题（问答、摘要等），都可以使用索引来检索相关信息。
- 查询接口：是输入查询并从 LLM 中获取知识增强输出的接口。

对于使用 LlamaIndex 框架实现一个 RAG 应用，核心在于把握好 LlamaIndex 中的几个高层次抽象数据结构。

#### （1）Indexing

Indexing 是 LlamaIndex 中的一个重要组件，用于将数据结构化以适应不同的用例。在构建 RAG 应用时，需要将文本数据转换为向量表示，并将这些向量表示存储在向量数据库中。Indexing 将数据存储在Node对象（代表原始文档的 chunk ）中，支持额外配置和自动化的Retriever接口，可以帮助将这些向量表示分割、定义关系和组织，以便检索器可以从中检索出相关的文本片段。

#### （2）Vector Stores

Vector Stores 是 LlamaIndex 中的另一个重要组件，用于存储向量化的文本信息。在构建 RAG 应用时，需要将文本数据转换为向量表示，并将这些向量表示存储在向量数据库中。Vector Stores 提供了向量数据库的功能，可以帮助将向量化的文本信息持久化，存储在数据库中，然后我们可以使用检索器从数据库中检索出相关的文本片段。

#### （3）Query Engine

Query Engine 也是 LlamaIndex 中的一个重要组件，用于处理用户的查询请求。在构建 RAG 应用时，用户输入问题，Query Engine 会将问题转换为向量表示，然后使用检索器从向量数据库中检索出相关的文本片段，最后使用生成器根据检索到的文本片段生成答案。

通过 index 、vector store、 query engine 的构建，我们可以很容易针对不同抽象组织的 chunk 进行我们想要的检索、查询操作，最终得到高质量的 RAG 系统。

#### （4）总结实战

在实际应用中，我们可以使用 LlamaIndex 框架构建一个 RAG 应用，主要包括以下几个步骤：

- 初始化所有资源：嵌入模型（Embedding）、LLM、LlamaIndex组件
- 文档准备：将文档载入，并使用 LlamaIndex 的 Indexing 组件将文档转换为向量表示，使用 Vector Stores 将其持久化于本地磁盘中
- 向量检索：接受用户交互，将用户输入的问题转换为向量表示，使用 Query Engine 从 Vector Stores 中检索出相关的文本片段
- LLM 生成：综合所有文本内容，包括用户问题和检索结果，让 LLM 生成特定答案

### 3. 使用 LangChain 框架构建 RAG 应用

LangChain 是一个基于 Python 的自然语言处理开源框架，提供了一系列 NLP 模型和工具，可以帮助用户快速构建 NLP 应用。LangChain 提供了一系列 NLP 模型和工具，包括文本向量化、文本检索、文本生成等功能，可以帮助用户快速构建 RAG 应用。

LangChain 的核心包括 Chains 和 I/O 模块。

- Chains：将组件组合实现端到端应用，通过一个对象封装实现一系列 LLM 操作（如检索问答链，覆盖实现了 RAG 的全部流程）。
- I/O：提供了 LLM 模型的输入输出接口，可以帮助用户快速实现 LLM 模型的输入输出。

#### （1）Chain

Chain（链）是 LangChain 组件中十分核心的概念，它将组件组合实现端到端应用，通过一个对象封装实现一系列 LLM 操作。在构建 RAG 应用时，可以使用 LangChain 提供的检索问答链模版，自动实现知识检索、Prompt 嵌入、LLM 问答的全部流程。

#### （2）I/O

I/O 负责了 LangChain 应用中所有的输入输出，包括文本向量化、文本检索、文本生成等功能。在构建 RAG 应用时，可以使用 LangChain 提供的 I/O 模块，帮助用户快速实现 LLM 模型的输入输出。

通过 Chain 和 I/O 的组合，再加上 LangChain 本身内含的多种文本处理工具和对多种数据库的兼容性工具，我们可以很容易构建一个 RAG 应用，实现用户输入问题，模型生成答案的功能。

#### （3）总结实战

在实际应用中，我们可以使用 LangChain 框架构建一个 RAG 应用，主要包括以下几个步骤：

- 初始化所有资源：嵌入模型（Embedding）、LLM
- 文档准备：使用 LangChain 的文档载入工具载入，使用 LangChain 的工具对文档进行切片处理，使用 LangChain 的向量化工具将文档转换为向量表示，存入数据库中
- 向量检索：接受用户交互，将用户输入的问题转换为向量表示，使用 LangChain 的检索问答链（RetrievalQAChain）从持久化的数据库中检索出相关的文本片段
- LLM 生成：综合所有文本内容，包括用户问题和检索结果，使用 LLM 链（LLMChain）与 LLM 交流，让 LLM 生成特定答案

## 三、总结

本文主要介绍了 RAG 应用的基本原理和实现方法，以及如何使用 LlamaIndex 框架或 LangChain 框架构建一个带前端网页界面 RAG 应用。通过构建 RAG 应用，可以实现更加准确和高效的问答系统，提高用户体验。

## 参考文章

- [Task3：实现 RAG 应用 - Datawhale AI 夏令营](https://datawhaler.feishu.cn/wiki/R78xwbV1DiqZpwkO7M5cHtCmnof)
- [Tutorials - LangChain](https://python.langchain.com/v0.2/docs/tutorials/)

